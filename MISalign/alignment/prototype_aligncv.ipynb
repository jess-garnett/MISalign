{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Data Ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototyping_datafolder=r\"C:\\Users\\drago\\Box\\p_MIS-MISalign\\data_AlignCV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir,path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=dict()\n",
    "for datafolder in listdir(prototyping_datafolder):\n",
    "    for sample in listdir(path.join(prototyping_datafolder,datafolder)):\n",
    "        entry=dict()\n",
    "        entry[\"dataset\"]=datafolder\n",
    "        entry[\"path\"]=path.join(prototyping_datafolder,datafolder,sample)\n",
    "        data_set[sample]=entry\n",
    "df=pd.DataFrame(data_set).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0].path)\n",
    "display(df[df.dataset==\"data_nov\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PILImage.open(df.iloc[0].path).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.opencv.org/4.x/d5/de5/tutorial_py_setup_in_windows.html\n",
    "# https://pypi.org/project/opencv-python/#manual-builds\n",
    "# %pip install opencv-python\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html\n",
    "# https://docs.opencv.org/4.x/db/d27/tutorial_py_table_of_contents_feature2d.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT https://docs.opencv.org/4.x/da/df5/tutorial_py_sift_intro.html\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "img = cv.imread(df.iloc[0].path)\n",
    "gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    " \n",
    "sift = cv.SIFT_create()\n",
    "kp = sift.detect(gray,None)\n",
    " \n",
    "# img=cv.drawKeypoints(gray,kp,img)\n",
    "img=cv.drawKeypoints(gray,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    " \n",
    "# cv.imshow('sift_keypoints',img)\n",
    "PILImage.fromarray(img).show()\n",
    "# display(PILImage.fromarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp,des = sift.compute(gray,kp)\n",
    "display(des.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.opencv.org/4.x/d1/d89/tutorial_py_orb.html\n",
    "img = cv.imread(df.iloc[-2].path)\n",
    "gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Initiate ORB detector\n",
    "orb = cv.ORB_create(nfeatures=500,edgeThreshold=5)\n",
    " \n",
    "# find the keypoints with ORB\n",
    "kp = orb.detect(gray,None)\n",
    " \n",
    "# compute the descriptors with ORB\n",
    "kp, des = orb.compute(gray, kp)\n",
    " \n",
    "# draw only keypoints location,not size and orientation\n",
    "# img2 = cv.drawKeypoints(gray, kp, None, color=(0,255,0), flags=0)\n",
    "img2=cv.drawKeypoints(gray,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "PILImage.fromarray(img2).show()\n",
    "# PILImage.fromarray(img2).save(\"241210_ORB_sem3_nf500_et5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(des.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.opencv.org/4.x/dc/dc3/tutorial_py_matcher.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brute-Force Matching w/ ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "img1 = cv.imread(df.iloc[0].path,cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "img2 = cv.imread(df.iloc[1].path,cv.IMREAD_GRAYSCALE) # trainImage\n",
    " \n",
    "# Initiate ORB detector\n",
    "orb = cv.ORB_create()\n",
    " \n",
    "# find the keypoints and descriptors with ORB\n",
    "kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "kp2, des2 = orb.detectAndCompute(img2,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create BFMatcher object\n",
    "bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    " \n",
    "# Match descriptors.\n",
    "matches = bf.match(des1,des2)\n",
    " \n",
    "# Sort them in the order of their distance.\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    " \n",
    "# Draw first 10 matches.\n",
    "img3 = cv.drawMatches(img1,kp1,img2,kp2,matches[:10],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    " \n",
    "plt.imshow(img3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp2[matches[0].trainIdx].pt\n",
    "kp1[matches[0].queryIdx].pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,match in enumerate(matches[:]):\n",
    "    train_pt=kp2[match.trainIdx].pt\n",
    "    query_pt=kp1[match.queryIdx].pt\n",
    "    x_offset=train_pt[0]-query_pt[0]\n",
    "    y_offset=train_pt[1]-query_pt[1]\n",
    "    # print([x_offset],[y_offset])\n",
    "    # plt.plot([0,x_offset],[0,y_offset],alpha=0.1)\n",
    "    plt.plot([x_offset],[y_offset],\"o\",alpha=0.05,markersize=20)\n",
    "    if i<50:\n",
    "        plt.plot([0,x_offset],[0,y_offset],alpha=0.05)\n",
    "plt.xlim([-1200,1200])\n",
    "plt.ylim([-800,800])\n",
    "plt.title(\"Matches Visualized - all matches dots - top 50 matches lines - 0.05 alpha\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paused to focus on moving forward with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paused to focus on moving forward with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_df=df[df.dataset==\"data_hdf\"].copy() # 2x2 high distinct feature set\n",
    "set_df=df[df.dataset==\"data_sem\"].copy() # 4x1 low overlap set\n",
    "set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_data=dict()\n",
    "for name,sample in set_df.iterrows():\n",
    "    # print(sample)\n",
    "    img = cv.imread(sample.path, cv.IMREAD_GRAYSCALE)\n",
    "    orb = cv.ORB_create(edgeThreshold=5)\n",
    "    kp, des = orb.detectAndCompute(img,None)\n",
    "    orb_data[name]={\"img\":img,\"kp\":kp,\"des\":des}\n",
    "orb_df=pd.DataFrame(orb_data).T\n",
    "orb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width=2560\n",
    "img_height=1672\n",
    "match_combs=combinations(set_df.index.to_list(),2)\n",
    "# print(list(match_combs))\n",
    "match_data=dict()\n",
    "for m1,m2 in match_combs:\n",
    "    print(m1,m2)\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(orb_df[\"des\"][m1],orb_df[\"des\"][m2])\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    img3 = cv.drawMatches(orb_df[\"img\"][m1],orb_df[\"kp\"][m1],orb_df[\"img\"][m2],orb_df[\"kp\"][m2],matches[:10],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    plt.imshow(img3)\n",
    "    plt.savefig(f\"241211_OCV_MOSet_{m1[7:11]}-{m2[10:11]}-matches.png\",bbox_inches=\"tight\",dpi=300)\n",
    "    plt.show()\n",
    "    for i,match in enumerate(matches[:]):\n",
    "        train_pt=orb_df[\"kp\"][m2][match.trainIdx].pt\n",
    "        query_pt=orb_df[\"kp\"][m1][match.queryIdx].pt\n",
    "        x_offset=train_pt[0]-query_pt[0]\n",
    "        y_offset=train_pt[1]-query_pt[1]\n",
    "        plt.plot([x_offset],[y_offset],\"o\",alpha=0.05,markersize=20)\n",
    "        if i<50:\n",
    "            plt.plot([0,x_offset],[0,y_offset],alpha=0.05)\n",
    "    plt.xlim([-img_width,img_width])\n",
    "    plt.ylim([-img_height,img_height])\n",
    "    plt.savefig(f\"241211_OCV_MOSet_{m1[7:11]}-{m2[10:11]}-offsets.png\",bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offset Determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototyping\n",
    "- lro2-3 for clean-defined\n",
    "- lro0-2 for fuzzy rotated\n",
    "- lro1-2 for similar feature but no match\n",
    "- hdf0-2 for corner barely match\n",
    "- hdf0-1 for clean-defined\n",
    "- hdf1-3 for clean-defined\n",
    "- lov2-3 for fuzzy match\n",
    "- lov1-2 for fuzzy match\n",
    "- ldf0-3 for clean match w/ noise\n",
    "- ldf2-3 for clean match w/ noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_short=[\"sem0\",\"sem1\",\"sem2\",\"sem3\",\"sem4\",\"sem5\"]#[\"lro0\",\"lro1\",\"lro2\",\"lro3\",\"hdf0\",\"hdf1\",\"hdf2\",\"hdf3\",\"lov1\",\"lov2\",\"lov3\",\"ldf0\",\"ldf2\",\"ldf3\"]\n",
    "samples=pd.DataFrame([df[df.index.str.contains(x)].iloc[0] for x in samples_short])\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_data=dict()\n",
    "for name,sample in samples.iterrows():\n",
    "    # print(sample)\n",
    "    img = cv.imread(sample.path, cv.IMREAD_GRAYSCALE)\n",
    "    orb = cv.ORB_create(nfeatures=500,edgeThreshold=5)\n",
    "    kp, des = orb.detectAndCompute(img,None)\n",
    "    orb_data[name]={\"img\":img,\"kp\":kp,\"des\":des}\n",
    "orb_df=pd.DataFrame(orb_data).T\n",
    "orb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_combs=combinations(orb_df.index.to_list(),2)\n",
    "# match_combs=((\"lro2\",\"lro3\"),(\"lro0\",\"lro2\"),(\"lro1\",\"lro2\"),(\"hdf0\",\"hdf2\"),(\"hdf0\",\"hdf1\"),(\"hdf1\",\"hdf3\"),(\"lov2\",\"lov3\"),(\"lov1\",\"lov2\"),(\"ldf0\",\"ldf3\"),(\"ldf2\",\"ldf3\"))\n",
    "# match_combs=((\"sem0\",\"sem1\"),(\"sem2\",\"sem3\"),(\"sem3\",\"sem4\"),(\"sem4\",\"sem5\"),(\"sem3\",\"sem5\"))\n",
    "match_combs=((\"sem0\",\"sem1\"),(\"sem2\",\"sem3\"),(\"sem3\",\"sem4\"),(\"sem4\",\"sem5\"),(\"sem3\",\"sem5\"))\n",
    "match_combs=[(df.index[df.index.str.contains(x[0])][0],df.index[df.index.str.contains(x[1])][0]) for x in match_combs]\n",
    "\n",
    "match_combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width=2560\n",
    "img_height=1672\n",
    "for m1,m2 in match_combs:\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(orb_df[\"des\"][m1],orb_df[\"des\"][m2])\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    print([m.distance for m in matches])\n",
    "    offset_grid=np.zeros((2*img_width,2*img_height),dtype=float) # change this to match 2x image distance.(3200,2400)\n",
    "    for i,match in enumerate(matches[:]):\n",
    "        train_pt=orb_df[\"kp\"][m2][match.trainIdx].pt\n",
    "        query_pt=orb_df[\"kp\"][m1][match.queryIdx].pt\n",
    "        x_offset_adj=int(train_pt[0]-query_pt[0]+img_width) #1600/1200 centers in numpy array/image.\n",
    "        y_offset_adj=int(train_pt[1]-query_pt[1]+img_height)\n",
    "        offset_grid[x_offset_adj,y_offset_adj]+=1000/(match.distance**2)\n",
    "    offset_grid=ndimage.gaussian_filter(offset_grid,10)\n",
    "    print(m1,m2,\"Offset:\",np.array(np.unravel_index(np.argmax(offset_grid),offset_grid.shape))-np.array([img_width,img_height]))\n",
    "    plt.title(\" \".join([m1,m2,str(tuple(np.array(np.unravel_index(np.argmax(offset_grid),offset_grid.shape))-np.array([img_width,img_height]))),f\"{offset_grid.max():.5f}\"]))\n",
    "    plt.imshow(offset_grid.T)\n",
    "    plt.colorbar()\n",
    "    plt.savefig(f\"241210_OffsetMap_{m1[7:11]}-{m2[10:11]}-offmap-1000imds-g10_nf500_et5.png\",bbox_inches=\"tight\",dpi=300)\n",
    "    plt.show()\n",
    "    # img3 = cv.drawMatches(orb_df[\"img\"][m1],orb_df[\"kp\"][m1],orb_df[\"img\"][m2],orb_df[\"kp\"][m2],matches[:10],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    # plt.imshow(img3)\n",
    "    # plt.savefig(f\"240815_OCV_MOSet_{m1[7:11]}-{m2[10:11]}-matches.png\",bbox_inches=\"tight\",dpi=300)\n",
    "    # plt.show()\n",
    "    # for i,match in enumerate(matches[:]):\n",
    "    #     train_pt=orb_df[\"kp\"][m2][match.trainIdx].pt\n",
    "    #     query_pt=orb_df[\"kp\"][m1][match.queryIdx].pt\n",
    "    #     x_offset=train_pt[0]-query_pt[0]\n",
    "    #     y_offset=train_pt[1]-query_pt[1]\n",
    "    #     plt.plot([x_offset],[y_offset],\"o\",alpha=0.05,markersize=20)\n",
    "    #     if i<50:\n",
    "    #         plt.plot([0,x_offset],[0,y_offset],alpha=0.05)\n",
    "    # plt.xlim([-1600,1600])\n",
    "    # plt.ylim([-1200,1200])\n",
    "    # plt.savefig(f\"240815_OCV_MOSet_{m1[7:11]}-{m2[10:11]}-offsets.png\",bbox_inches=\"tight\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing way to get/compare local maxima. Code from `https://stackoverflow.com/questions/9111711/get-coordinates-of-local-maxima-in-2d-array-above-certain-value`\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "neighborhood_size = 50\n",
    "threshold = 0.0005\n",
    "\n",
    "data = offset_grid.T\n",
    "\n",
    "data_max = ndimage.maximum_filter(data, neighborhood_size)\n",
    "maxima = (data == data_max)\n",
    "data_min = ndimage.minimum_filter(data, neighborhood_size)\n",
    "diff = ((data_max - data_min) > threshold)\n",
    "maxima[diff == 0] = 0\n",
    "\n",
    "labeled, num_objects = ndimage.label(maxima)\n",
    "xy = np.array(ndimage.center_of_mass(data, labeled, range(1, num_objects+1)))\n",
    "\n",
    "plt.imshow(data)\n",
    "\n",
    "plt.autoscale(False)\n",
    "plt.plot(xy[:, 1], xy[:, 0], 'rx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-array/blended match>offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_from=\"sample_sem0.tif\"\n",
    "# image_to=\"sample_sem1.tif\"\n",
    "# sem 0 to sem 1: [48 1101] from offset map\n",
    "# image_from=\"sample_sem3.tif\"\n",
    "# image_to=\"sample_sem5.tif\"\n",
    "# sem 3 to sem 5: No real relation\n",
    "image_from=\"sample_sem3.tif\"\n",
    "image_to=\"sample_sem4.tif\"\n",
    "# 3>4 has distinct relation in offset map\n",
    "\n",
    "matches = bf.match(orb_df[\"des\"][image_from],orb_df[\"des\"][image_to])\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "pts_from=np.array([orb_df[\"kp\"][image_from][match.queryIdx].pt for match in matches])\n",
    "pts_to=np.array([orb_df[\"kp\"][image_to][match.trainIdx].pt for match in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "eAP2D=cv.estimateAffinePartial2D(pts_from,pts_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X,Y:\",eAP2D[0][:,2])\n",
    "#cos^2 + sin^2 = 1 >> rotation/scale component of matrix =s^2\n",
    "print(\"Rotation & Scale Matrix:\",eAP2D[0][:,:2])\n",
    "eAP2D_scalex=(eAP2D[0][0,0]**2+eAP2D[0][0,1]**2)**0.5\n",
    "eAP2D_scaley=(eAP2D[0][1,1]**2+eAP2D[0][1,0]**2)**0.5\n",
    "print(\"Scale X,Y:\",[eAP2D_scalex,eAP2D_scaley])\n",
    "eAP2D_rotation=np.arctan(eAP2D[0][0,1]/eAP2D[0][1,1])\n",
    "print(\"Rotation(Rad/Deg):\",eAP2D_rotation,\"/\",eAP2D_rotation*180/np.pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Inliers:\",np.sum(eAP2D[1]))\n",
    "for pt_from,pt_to,in_out in zip(pts_from,pts_to,eAP2D[1]):\n",
    "    if in_out:\n",
    "        print(\"X,Y:\",pt_to[0]-pt_from[0],pt_to[1]-pt_from[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set implementation\n",
    "Also grabbing all need coded/imports/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "from math import dist\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run data import from first section to setup `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_short=[\"sem0\",\"sem1\",\"sem2\",\"sem3\",\"sem4\",\"sem5\"]#\n",
    "# samples_short=[\"lro0\",\"lro1\",\"lro2\",\"lro3\",\"hdf0\",\"hdf1\",\"hdf2\",\"hdf3\",\"lov1\",\"lov2\",\"lov3\",\"ldf0\",\"ldf2\",\"ldf3\"]\n",
    "samples=pd.DataFrame([df[df.index.str.contains(x)].iloc[0] for x in samples_short])\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_combs=combinations(orb_df.index.to_list(),2)\n",
    "match_combs=((\"sem0\",\"sem1\"),(\"sem2\",\"sem3\"),(\"sem3\",\"sem4\"),(\"sem4\",\"sem5\"),(\"sem3\",\"sem5\"))\n",
    "# match_combs=((\"lro2\",\"lro3\"),(\"lro0\",\"lro2\"),(\"lro1\",\"lro2\"),(\"hdf0\",\"hdf2\"),(\"hdf0\",\"hdf1\"),(\"hdf1\",\"hdf3\"),(\"lov2\",\"lov3\"),(\"lov1\",\"lov2\"),(\"ldf0\",\"ldf3\"),(\"ldf2\",\"ldf3\"))\n",
    "# match_combs=((\"lov2\",\"lov3\"),(\"lov1\",\"lov2\"),(\"ldf0\",\"ldf3\"))\n",
    "match_combs=[(df.index[df.index.str.contains(x[0])][0],df.index[df.index.str.contains(x[1])][0]) for x in match_combs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_data=dict()\n",
    "for name,sample in samples.iterrows():\n",
    "    # print(sample)\n",
    "    img = cv.imread(sample.path, cv.IMREAD_GRAYSCALE)\n",
    "    orb = cv.ORB_create(nfeatures=4000,edgeThreshold=5)\n",
    "    kp, des = orb.detectAndCompute(img,None)\n",
    "    orb_data[name]={\"img\":img,\"kp\":kp,\"des\":des}\n",
    "orb_df=pd.DataFrame(orb_data).T\n",
    "orb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_refs={#values for offset from offsetmap\n",
    "    (\"sem0\",\"sem1\"):[48, 1101],\n",
    "    (\"sem2\",\"sem3\"):[84, 1192],\n",
    "    (\"sem3\",\"sem4\"):[14, 682],\n",
    "    (\"sem4\",\"sem5\"):[1,1558],\n",
    "    (\"sem3\",\"sem5\"):[673,-538]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m1,m2 in match_combs:\n",
    "    print(m1,m2)\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "    \n",
    "    matches = bf.match(orb_df[\"des\"][m1],orb_df[\"des\"][m2])\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    matches = matches[:int(len(matches)*(1/8))]\n",
    "    # matches = matches[:10]\n",
    "\n",
    "    pts_from=np.array([orb_df[\"kp\"][m1][match.queryIdx].pt for match in matches])\n",
    "    pts_to=np.array([orb_df[\"kp\"][m2][match.trainIdx].pt for match in matches])\n",
    "\n",
    "    eAP2D=cv.estimateAffinePartial2D(pts_from,pts_to)\n",
    "\n",
    "    eAP2D_translationx=eAP2D[0][0,2]\n",
    "    eAP2D_translationy=eAP2D[0][1,2]\n",
    "    print(f\"X,Y:{eAP2D_translationx:0.1f}, {eAP2D_translationy:0.1f}\")\n",
    "    print(\"Rotation & Scale Matrix: \\n\",eAP2D[0][:,:2])\n",
    "    eAP2D_scalex=(eAP2D[0][0,0]**2+eAP2D[0][0,1]**2)**0.5\n",
    "    eAP2D_scaley=(eAP2D[0][1,1]**2+eAP2D[0][1,0]**2)**0.5\n",
    "    print(f\"Scale X,Y: {eAP2D_scalex:0.3f}, {eAP2D_scaley:0.3f}\")\n",
    "    eAP2D_rotation=np.arctan(eAP2D[0][0,1]/eAP2D[0][1,1])\n",
    "    print(f\"Rotation(Rad/Deg): {eAP2D_rotation:0.3f} /{eAP2D_rotation*180/np.pi:0.1f}\")\n",
    "    print(\"Inliers:\",np.sum(eAP2D[1]))\n",
    "    for pt_from,pt_to,in_out in zip(pts_from,pts_to,eAP2D[1]):\n",
    "        if in_out:\n",
    "            print(f\"X,Y:{pt_from[0]-pt_to[0]:0.1f}, {pt_from[1]-pt_to[1]:0.1f}\")\n",
    "    \n",
    "    distances_inlier=np.array([(i,match.distance) for i,(match,in_out) in enumerate(zip(matches,eAP2D[1])) if in_out])\n",
    "    distances_outlier=np.array([(i,match.distance) for i,(match,in_out) in enumerate(zip(matches,eAP2D[1])) if not in_out])\n",
    "    plt.figure()\n",
    "    plt.plot(distances_inlier[:,0],distances_inlier[:,1],\"gx\")\n",
    "    try:\n",
    "        plt.plot(distances_outlier[:,0],distances_outlier[:,1],\"r.\")\n",
    "    except IndexError:\n",
    "        print(\"No Outliers\")\n",
    "    plt.xlabel(\"match index\")\n",
    "    plt.ylabel(\"match distance\")\n",
    "    plt.title(f\"{m1}-{m2} in/out distances\")\n",
    "    plt.show()\n",
    "\n",
    "    # ### Sanity check with offset map\n",
    "    # img_width=1600#2560\n",
    "    # img_height=1200#1672\n",
    "    # offset_grid=np.zeros((2*img_width,2*img_height),dtype=float) # change this to match 2x image distance.(3200,2400)\n",
    "    # for i,match in enumerate(matches[:]):\n",
    "    #     train_pt=orb_df[\"kp\"][m2][match.trainIdx].pt\n",
    "    #     query_pt=orb_df[\"kp\"][m1][match.queryIdx].pt\n",
    "    #     x_offset_adj=int(train_pt[0]-query_pt[0]+img_width) #1600/1200 centers in numpy array/image.\n",
    "    #     y_offset_adj=int(train_pt[1]-query_pt[1]+img_height)\n",
    "    #     offset_grid[x_offset_adj,y_offset_adj]+=1000/(match.distance**2)\n",
    "    # offset_grid=ndimage.gaussian_filter(offset_grid,10)\n",
    "    # print(m1,m2,\"Offset:\",np.array(np.unravel_index(np.argmax(offset_grid),offset_grid.shape))-np.array([img_width,img_height]))\n",
    "    # plt.title(\" \".join([m1,m2,str(tuple(np.array(np.unravel_index(np.argmax(offset_grid),offset_grid.shape))-np.array([img_width,img_height]))),f\"{offset_grid.max():.5f}\"]))\n",
    "    # plt.imshow(offset_grid.T)\n",
    "    # plt.colorbar()\n",
    "    # # plt.savefig(f\"241210_OffsetMap_{m1[7:11]}-{m2[10:11]}-offmap-1000imds-g10_nf500_et5.png\",bbox_inches=\"tight\",dpi=300)\n",
    "    # plt.show()\n",
    "    # match_refs[(m1[7:11],m2[7:11])]=list(np.array(np.unravel_index(np.argmax(offset_grid),offset_grid.shape))-np.array([img_width,img_height]))\n",
    "    # ###\n",
    "\n",
    "    top10_offsets=np.array([(pt_to[0]-pt_from[0],pt_to[1]-pt_from[1]) for pt_from,pt_to in zip(pts_from[:int(len(matches)*(1/10))],pts_to[:int(len(matches)*(1/10))])])\n",
    "    top50_offsets=np.array([(pt_to[0]-pt_from[0],pt_to[1]-pt_from[1]) for pt_from,pt_to in zip(pts_from[int(len(matches)*(1/10)):int(len(matches)*(1/2))],pts_to[int(len(matches)*(1/10)):int(len(matches)*(1/2))])])\n",
    "    remaining_offsets=np.array([(pt_to[0]-pt_from[0],pt_to[1]-pt_from[1]) for pt_from,pt_to in zip(pts_from[int(len(matches)*(1/2)):],pts_to[int(len(matches)*(1/2)):])])\n",
    "    plt.figure()\n",
    "    plt.plot(top10_offsets[:,0],top10_offsets[:,1],\"gx\",alpha=0.1)\n",
    "    plt.plot(top50_offsets[:,0],top50_offsets[:,1],\"yx\",alpha=0.1)\n",
    "    plt.plot(remaining_offsets[:,0],remaining_offsets[:,1],\"rx\",alpha=0.1)\n",
    "    plt.xlabel(\"x offset\")\n",
    "    plt.ylabel(\"y offset\")\n",
    "    plt.title(f\"{m1}-{m2} match offsets top 10%/top 50%/remaining\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    distances_metric_ref=np.array([(dist((pt_to[0]-pt_from[0],pt_to[1]-pt_from[1]),match_refs[(m1[7:11],m2[7:11])]),match.distance) for match,pt_from,pt_to in zip(matches,pts_from,pts_to)])\n",
    "    plt.figure()\n",
    "    plt.plot(distances_metric_ref[:,0],distances_metric_ref[:,1],\"x\")\n",
    "    plt.xlabel(\"ref distance\")\n",
    "    plt.ylabel(\"match distance\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.title(f\"{m1}-{m2} ref/match distances\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # plt.title(\" \".join([m1,m2,str(tuple(np.array(np.unravel_index(np.argmax(offset_grid),offset_grid.shape))-np.array([img_width,img_height]))),f\"{offset_grid.max():.5f}\"]))\n",
    "    # plt.imshow(offset_grid.T)\n",
    "    # plt.colorbar()\n",
    "    # plt.savefig(f\"241210_OffsetMap_{m1[7:11]}-{m2[10:11]}-offmap-1000imds-g10_nf500_et5.png\",bbox_inches=\"tight\",dpi=300)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionalizing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import abspath\n",
    "from sys import path\n",
    "path.insert(0, abspath(\"../..\"))  # Repository directory relative to this file.\n",
    "from MISalign.model.mis_file import MisFile,load_mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_filepath=r\"..\\\\..\\example\\data\\set_a\\mymis_calibrated.mis\"\n",
    "mis_project=load_mis(mis_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_myimages01.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\git_gh\\\\MISalign\\\\example\\\\data\\\\set_a\\\\a_myimages01.jpg',\n",
       " 'a_myimages02.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\git_gh\\\\MISalign\\\\example\\\\data\\\\set_a\\\\a_myimages02.jpg',\n",
       " 'a_myimages03.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\git_gh\\\\MISalign\\\\example\\\\data\\\\set_a\\\\a_myimages03.jpg',\n",
       " 'a_myimages04.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\git_gh\\\\MISalign\\\\example\\\\data\\\\set_a\\\\a_myimages04.jpg',\n",
       " 'a_myimages05.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\git_gh\\\\MISalign\\\\example\\\\data\\\\set_a\\\\a_myimages05.jpg',\n",
       " 'a_myimages06.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\git_gh\\\\MISalign\\\\example\\\\data\\\\set_a\\\\a_myimages06.jpg',\n",
       " 'a_myimages07.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\git_gh\\\\MISalign\\\\example\\\\data\\\\set_a\\\\a_myimages07.jpg',\n",
       " 'a_myimages08.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\git_gh\\\\MISalign\\\\example\\\\data\\\\set_a\\\\a_myimages08.jpg',\n",
       " 'a_myimages09.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\git_gh\\\\MISalign\\\\example\\\\data\\\\set_a\\\\a_myimages09.jpg',\n",
       " 'a_myimages10.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\git_gh\\\\MISalign\\\\example\\\\data\\\\set_a\\\\a_myimages10.jpg'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_project.get_image_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a_myimages01.jpg',\n",
       " 'a_myimages02.jpg',\n",
       " 'a_myimages03.jpg',\n",
       " 'a_myimages04.jpg',\n",
       " 'a_myimages05.jpg',\n",
       " 'a_myimages06.jpg',\n",
       " 'a_myimages07.jpg',\n",
       " 'a_myimages08.jpg',\n",
       " 'a_myimages09.jpg',\n",
       " 'a_myimages10.jpg']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mis_project.get_image_paths().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageManager():\n",
    "    def __init__(self,image_names_paths:dict):\n",
    "        self.image_dict={name:{\"path\":filepath} for name,filepath in image_names_paths.items()}\n",
    "    \n",
    "    def get_names(self)->list[str]:\n",
    "        return list(self.image_dict.keys())\n",
    "    def get_path(self,name:str)->str:\n",
    "        return self.image_dict[name][\"path\"]\n",
    "    def lookup_name(self,short_name:str)->str:\n",
    "        name_matches=[name for name in self.image_dict.keys() if short_name in name]\n",
    "        if len(name_matches)==1:\n",
    "            return name_matches\n",
    "        elif len(name_matches)==0:\n",
    "            raise ValueError(f\"short_name '{short_name}' matched no image names.\")\n",
    "        elif len(name_matches)>1:\n",
    "            raise ValueError(f\"short_name '{short_name}' matched {len(name_matches)} image names: {name_matches}\")\n",
    "\n",
    "class ORBManager():\n",
    "    def __init__(self,\n",
    "            ImageM:ImageManager,\n",
    "            precompute_default=True,\n",
    "            store_compute=True,\n",
    "            default_ORB_parameters={\"nfeatures\":500,\"edgeThreshold\":5}):\n",
    "        self.ImageM=ImageM\n",
    "        self.default_ORB_parameters=default_ORB_parameters\n",
    "        self.store_compute=store_compute\n",
    "        if store_compute:\n",
    "            self.computed=dict()\n",
    "            if precompute_default:\n",
    "                for image_name in ImageM.get_names():\n",
    "                    self.computed[image_name]=dict()\n",
    "                    self.computed[image_name][self.get_parameter_hashable(default_ORB_parameters)]=self.compute_orb(image_name,default_ORB_parameters)\n",
    "\n",
    "    def compute_orb(self,image_name,ORB_parameters):\n",
    "        img = cv.imread(self.ImageM.get_path(image_name), cv.IMREAD_GRAYSCALE)\n",
    "        orb = cv.ORB_create(**ORB_parameters)\n",
    "        kp, des = orb.detectAndCompute(img,None)\n",
    "        return {\"kp\":kp,\"des\":des}\n",
    "    def get_parameter_hashable(self,ORB_parameters:dict)->tuple:\n",
    "        return tuple((k,ORB_parameters[k]) for k in sorted(ORB_parameters))\n",
    "    def get_orb(self,image_name,ORB_parameters=None):\n",
    "        if ORB_parameters is None:\n",
    "            ORB_parameters=self.default_ORB_parameters\n",
    "        ORB_parameter_hashable=self.get_parameter_hashable(ORB_parameters)\n",
    "        if self.store_compute:\n",
    "            if image_name in self.computed.keys():\n",
    "                if ORB_parameter_hashable in self.computed[image_name].keys():\n",
    "                    return self.computed[image_name][ORB_parameter_hashable]\n",
    "            else:\n",
    "                self.computed[image_name]=dict()\n",
    "        computed_orb=self.compute_orb(image_name,ORB_parameters)\n",
    "        if self.store_compute:\n",
    "            self.computed[image_name][ORB_parameter_hashable]=computed_orb\n",
    "        return computed_orb\n",
    "\n",
    "def generate_match_combinations(strategy,**kwargs)-> list[list]: \n",
    "    if strategy==\"order\":\n",
    "        return generate_match_combinations_in_order(kwargs[\"order\"])\n",
    "    elif strategy==\"short_pairs\":\n",
    "        return generate_match_combinations_from_short_pairs(kwargs[\"short_pairs\"],kwargs[\"short_lookup\"])\n",
    "    elif strategy==\"all\":\n",
    "        return generate_match_combinations_all_combinations(kwargs[\"all\"])\n",
    "    elif strategy==\"search\":\n",
    "        return generate_match_combinations_all_combinations(kwargs[\"search\"],kwargs[\"all\"])\n",
    "    else:\n",
    "        raise ValueError(f\"'{strategy}' is not a valid strategy.\")\n",
    "def generate_match_combinations_in_order(order:list):\n",
    "    return [[a,b] for a,b in zip(order[:-1],order[1:])]\n",
    "def generate_match_combinations_from_short_pairs(short_pairs:list[list],short_lookup:ImageManager.lookup_name):\n",
    "    pass #TODO\n",
    "def generate_match_combinations_all_combinations(items:list):\n",
    "    pass #TODO\n",
    "def generate_match_combinations_search(search:str,items:list):\n",
    "    pass #TODO\n",
    "\n",
    "def generate_match_bf(\n",
    "        image1:str,\n",
    "        image2:str,\n",
    "        match_reduction_ratio:float,\n",
    "        OrbM:ORBManager,\n",
    "        ORB_parameters:dict=None)->list[cv.DMatch]:\n",
    "    brute_force_matcher = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "    orb1=OrbM.get_orb(image1,ORB_parameters)\n",
    "    orb2=OrbM.get_orb(image2,ORB_parameters)\n",
    "    matches = brute_force_matcher.match(orb1[\"des\"],orb2[\"des\"])\n",
    "    sorted_matches = sorted(matches, key = lambda x:x.distance)\n",
    "    reduced_matches = matches[:int(len(sorted_matches)*(match_reduction_ratio))]\n",
    "    return reduced_matches,orb1,orb2\n",
    "\n",
    "def estimate_translation(\n",
    "        matches,\n",
    "        orb1,\n",
    "        orb2,\n",
    "        limit_affine_rotation=0.01, #maximum affine rotation without correction i.e. -0.01rad to +0.01rad rotations are acceptable.\n",
    "        limit_affine_scale=0.01, #maximum affine scale without correction i.e. 0.99 scale to 1.01 scale are acceptable.\n",
    "        limit_minimum_points=5, #minimum number of matched points for succesful translation estimate.\n",
    "        limit_inlier_consistency=0.5 #minimum fraction of matched points that must be consistent\n",
    "    )->list[list,bool]:\n",
    "    \n",
    "    pts_1=np.array([orb1[\"kp\"][match.queryIdx].pt for match in matches])\n",
    "    pts_2=np.array([orb2[\"kp\"][match.trainIdx].pt for match in matches])\n",
    "    eAP2D_matrix,eAP2D_in_out=cv.estimateAffinePartial2D(pts_1,pts_2)\n",
    "\n",
    "    eAP2D_translationx=eAP2D_matrix[0,2]\n",
    "    eAP2D_translationy=eAP2D_matrix[1,2]\n",
    "    # print(f\"X,Y:{eAP2D_translationx:0.1f}, {eAP2D_translationy:0.1f}\")\n",
    "    # print(\"Rotation & Scale Matrix: \\n\",eAP2D_matrix[:,:2])\n",
    "    eAP2D_scalex=(eAP2D_matrix[0,0]**2+eAP2D_matrix[0,1]**2)**0.5\n",
    "    eAP2D_scaley=(eAP2D_matrix[1,1]**2+eAP2D_matrix[1,0]**2)**0.5\n",
    "    # print(f\"Scale X,Y: {eAP2D_scalex:0.3f}, {eAP2D_scaley:0.3f}\")\n",
    "    eAP2D_rotation=np.arctan(eAP2D_matrix[0,1]/eAP2D_matrix[1,1])\n",
    "    # print(f\"Rotation(Rad/Deg): {eAP2D_rotation:0.3f} /{eAP2D_rotation*180/np.pi:0.1f}\")\n",
    "    # print(\"Inliers:\",np.sum(eAP2D[1]))\n",
    "    eAP2D_inliers=[(tuple(pt1),tuple(pt2)) for pt1,pt2,in_out in zip(pts_1,pts_2,eAP2D_in_out) if in_out]\n",
    "    eAP2D_inliers_count=len(eAP2D_inliers)\n",
    "    # for pt_from,pt_to,in_out in zip(pts_from,pts_to,eAP2D[1]):\n",
    "    #     if in_out:\n",
    "    #         print(f\"X,Y:{pt_from[0]-pt_to[0]:0.1f}, {pt_from[1]-pt_to[1]:0.1f}\")\n",
    "    #TODO verify based on limits\n",
    "    valid=True\n",
    "    return eAP2D_inliers, valid\n",
    "\n",
    "\n",
    "class AlignCVManager():\n",
    "    def __init__(self,ImageM:ImageManager,OrbM:ORBManager):\n",
    "        self.ImageM=ImageM\n",
    "        self.OrbM=OrbM\n",
    "        self.alignments=[]\n",
    "    def run_alignment(self,match_combinations,match_reduction_ratio=1/2,ORB_parameters=None):\n",
    "        alignment_data={\"alignment_parameters\":{\"match_combinations\":match_combinations,\"match_reduction_ratio\":match_reduction_ratio,\"ORB_parameters\":ORB_parameters},\"alignment_data\":dict()}\n",
    "        for image1,image2 in match_combinations:\n",
    "            image_set=(image1,image2)\n",
    "            matches,orb1,orb2=generate_match_bf(\n",
    "                image1=image1,\n",
    "                image2=image2,\n",
    "                match_reduction_ratio=match_reduction_ratio,\n",
    "                OrbM=self.OrbM,\n",
    "                ORB_parameters=ORB_parameters\n",
    "                )\n",
    "            estimated_translation_inliers, estimated_translation_validity = estimate_translation(matches,orb1,orb2)\n",
    "            alignment_data[\"alignment_data\"][image_set]={\n",
    "                \"matches\":matches,\n",
    "                \"estimated_translation_inliers\":estimated_translation_inliers,\n",
    "                \"estimated_translation_validity\":estimated_translation_validity\n",
    "                }\n",
    "        self.alignments.append(alignment_data)\n",
    "        return len(self.alignments)-1\n",
    "\n",
    "    def get_alignment(self,alignment_id):\n",
    "        return self.alignments[alignment_id]\n",
    "    #TODO valid results to mis\n",
    "    #TODO merging valid results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageM=ImageManager(mis_project.get_image_paths())\n",
    "\n",
    "OrbM=ORBManager(ImageM,default_ORB_parameters={\"nfeatures\": 2000,\"edgeThreshold\": 5 })\n",
    "\n",
    "AlignCVM=AlignCVManager(ImageM,OrbM)\n",
    "\n",
    "match_combinations=generate_match_combinations(strategy=\"order\",order=sorted(mis_project.get_image_names()))\n",
    "\n",
    "alignment_id=AlignCVM.run_alignment(match_combinations)\n",
    "alignment_result=AlignCVM.get_alignment(alignment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a_myimages01.jpg', 'a_myimages02.jpg'],\n",
       " ['a_myimages02.jpg', 'a_myimages03.jpg'],\n",
       " ['a_myimages03.jpg', 'a_myimages04.jpg'],\n",
       " ['a_myimages04.jpg', 'a_myimages05.jpg'],\n",
       " ['a_myimages05.jpg', 'a_myimages06.jpg'],\n",
       " ['a_myimages06.jpg', 'a_myimages07.jpg'],\n",
       " ['a_myimages07.jpg', 'a_myimages08.jpg'],\n",
       " ['a_myimages08.jpg', 'a_myimages09.jpg'],\n",
       " ['a_myimages09.jpg', 'a_myimages10.jpg']]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-10.0, 1085.0), (-9.0, 1086.0), (-8.4000244140625, 1087.1999969482422), (-9.39990234375, 1086.2000732421875), (-8.39996337890625, 1088.400047302246), (-9.60009765625, 1087.200023651123), (-9.1199951171875, 1088.4000244140625), (-9.8399658203125, 1085.2800521850586)]\n",
      "[(-9.0, 1147.0), (-9.0, 1148.0), (-8.0, 1146.0), (-8.0, 1145.0), (-10.0, 1146.60009765625), (-8.4000244140625, 1147.2000732421875), (-9.5999755859375, 1147.200023651123)]\n",
      "[(125.0, 1061.0), (125.0, 1061.0), (124.5999755859375, 1063.3999977111816), (124.0, 1060.0), (124.0, 1060.0), (122.39990234375, 1057.599998474121), (122.39990234375, 1058.9999961853027), (125.0, 1061.0), (125.0, 1061.0), (121.800048828125, 1059.0), (123.4000244140625, 1057.60009765625), (122.4000244140625, 1058.4000701904297), (124.08001708984375, 1061.0399932861328), (122.4000244140625, 1057.2000694274902), (124.800048828125, 1060.8000450134277), (125.52008056640625, 1061.0400466918945), (122.39990234375, 1058.400047302246), (124.79998779296875, 1063.4400482177734), (126.0, 1062.000072479248), (124.79998779296875, 1062.000072479248)]\n",
      "[(-10.0, 942.0), (-11.0, 944.0), (-11.0, 945.0), (-9.0, 943.0), (-10.0, 944.0), (-9.0, 943.0), (-9.0, 941.0), (-10.0, 942.0), (-9.20001220703125, 943.5999908447266), (-10.0, 943.0), (-9.0, 943.0), (-9.5999755859375, 940.800048828125), (-9.60009765625, 940.8000183105469), (-9.5999755859375, 942.0000457763672), (-8.4000244140625, 942.0000343322754), (-8.4000244140625, 943.2000122070312), (-9.5999755859375, 943.2000122070312), (-9.5999755859375, 943.2000961303711), (-8.4000244140625, 942.0000228881836), (-9.600006103515625, 943.2000122070312), (-10.0, 944.2000122070312), (-10.800048828125, 941.9999847412109), (-9.5999755859375, 942.0000152587891), (-10.0799560546875, 941.7600555419922), (-10.080078125, 941.7599945068359)]\n",
      "[(-7.0, 859.0), (-7.0, 859.0), (-7.0, 859.0), (-7.0, 858.0), (-6.0, 858.0), (-7.0, 859.0), (-6.0, 858.0), (-7.0, 858.0), (-7.0, 859.0), (-7.0, 859.0), (-6.0, 858.0), (-7.0, 859.0), (-6.0, 858.0), (-7.0, 859.0), (-6.0, 857.0), (-7.0, 857.0), (-7.0, 857.0), (-4.60003662109375, 855.9999847412109), (-6.0, 858.0), (-6.0, 858.0), (-7.0, 858.0), (-6.600006103515625, 856.5999908447266), (-7.0, 857.0), (-7.0, 858.0), (-6.0, 857.0), (-6.0, 857.0), (-6.0, 858.0), (-6.0, 858.0), (-8.0, 856.0), (-8.0, 855.0), (-6.0, 858.000036239624), (-5.79998779296875, 858.0000610351562), (-7.20001220703125, 858.0000114440918), (-6.0, 858.0000457763672), (-7.20001220703125, 859.200008392334), (-7.20001220703125, 859.2000350952148), (-5.03997802734375, 858.2400588989258), (-5.79998779296875, 858.4000244140625), (-6.0, 858.0000457763672), (-6.0, 859.2000350952148), (-6.79998779296875, 857.800048828125), (-7.199951171875, 856.8000335693359), (-7.43994140625, 856.3200836181641), (-6.0, 856.8000946044922), (-6.0, 858.0000457763672), (-6.240020751953125, 858.4800109863281), (-6.0, 857.9999847412109), (-6.0, 858.0000610351562), (-4.79998779296875, 858.0000152587891), (-7.0, 858.4000244140625), (-6.0, 858.0000305175781), (-6.0, 856.800048828125), (-5.199981689453125, 856.800048828125), (-7.20001220703125, 856.800048828125), (-8.87994384765625, 857.0401000976562), (-6.399993896484375, 857.2000732421875), (-7.199981689453125, 858.2400360107422), (-7.20001220703125, 858.2400054931641), (-5.760009765625, 856.8000640869141), (-6.04803466796875, 858.2400512695312), (-7.2000732421875, 856.8000602722168), (-7.20001220703125, 856.8000602722168), (-6.0, 857.5200538635254), (-7.20001220703125, 858.2400131225586), (-5.760009765625, 858.2400360107422), (-5.75994873046875, 858.2400302886963), (-6.47998046875, 857.2800140380859), (-7.20001220703125, 858.2400436401367), (-7.199981689453125, 858.2400588989258), (-6.47998046875, 856.0800628662109), (-7.199951171875, 858.2400512695312)]\n",
      "[(-7.4000244140625, 990.7999992370605), (-8.0, 991.0), (-8.0, 988.0), (-7.0, 990.0), (-7.0, 990.0), (-8.0, 990.0), (-7.0, 989.0), (-7.0, 990.0), (-7.0, 990.0), (-7.0, 991.0), (-7.0, 991.0), (-7.20001220703125, 991.200023651123), (-7.20001220703125, 991.2000961303711), (-7.199951171875, 991.1999969482422), (-7.2000732421875, 988.8000717163086), (-7.99993896484375, 990.800048828125), (-8.39990234375, 991.1999969482422), (-8.4000244140625, 990.0), (-7.20001220703125, 989.9999923706055), (-7.20001220703125, 991.2000885009766), (-7.20001220703125, 990.0000457763672), (-8.4000244140625, 991.2000732421875), (-8.0, 989.0), (-8.39990234375, 990.0000610351562), (-7.20001220703125, 990.0000152587891), (-7.20001220703125, 990.0000152587891), (-9.5999755859375, 989.800048828125), (-7.199981689453125, 991.2000732421875), (-7.199981689453125, 990.0000152587891), (-7.199951171875, 992.1600551605225)]\n",
      "[(-6.60003662109375, 1007.3999996185303), (-7.0, 1010.0), (-6.800018310546875, 1010.3999996185303), (-8.0, 1010.0), (-8.0, 1009.0), (-8.0, 1009.0), (-7.0, 1008.0), (-8.0, 1010.0), (-7.0, 1009.0), (-7.199951171875, 1008.0000228881836), (-8.4000244140625, 1009.2000484466553), (-8.39996337890625, 1009.1999969482422), (-7.2000732421875, 1008.0000457763672), (-7.20001220703125, 1009.1999969482422), (-8.4000244140625, 1010.4000968933105), (-8.4000244140625, 1006.8000411987305)]\n",
      "[(-9.0, 938.0), (-7.0, 940.0), (-7.20001220703125, 939.1999969482422), (-6.600006103515625, 939.0), (-8.0, 936.0), (-8.0, 941.0), (-8.0, 939.0), (-5.0, 938.0), (-7.60009765625, 938.5999984741211), (-8.0, 940.0), (-8.0, 939.0), (-8.0, 939.0), (-7.0, 939.0), (-7.0, 940.0), (-5.800048828125, 939.1999969482422), (-7.0, 938.0), (-7.0, 939.0), (-8.0, 936.0), (-7.0, 938.0), (-5.800048828125, 934.1999969482422), (-7.67999267578125, 938.8800239562988), (-7.199951171875, 936.0000343322754), (-7.20001220703125, 940.800048828125), (-7.20001220703125, 938.4000244140625), (-8.8800048828125, 939.1200942993164), (-6.39996337890625, 939.4000244140625), (-8.199951171875, 938.60009765625), (-7.20001220703125, 938.4000854492188), (-6.0, 938.4000701904297), (-6.0, 937.2000122070312), (-8.4000244140625, 936.0000457763672), (-8.39990234375, 935.52001953125), (-7.2000732421875, 938.0160255432129), (-8.6400146484375, 936.0000534057617), (-6.48004150390625, 939.3600196838379), (-8.6400146484375, 936.0000228881836), (-6.239990234375, 939.1200294494629), (-6.0, 934.3200302124023), (-7.199981689453125, 938.880012512207), (-8.6400146484375, 937.4400405883789), (-6.9119873046875, 937.4399871826172), (-9.12005615234375, 936.7200317382812), (-7.20001220703125, 938.8800811767578), (-7.199951171875, 938.8800811767578)]\n",
      "[(-4.0, 716.0), (-4.0, 714.0), (-4.0, 716.0), (-4.0, 715.0), (-4.0, 716.0), (-6.0, 716.0), (-5.0, 714.0), (-4.0, 716.0), (-4.0, 717.0), (-3.0, 716.0), (-5.0, 715.0), (-5.0, 714.0), (-5.0, 716.0), (-4.0, 715.0), (-5.0, 714.0), (-5.0, 715.0), (-4.0, 716.0), (-3.0, 715.0), (-3.0, 715.0), (-4.0, 716.0), (-5.4000244140625, 713.5999755859375), (-5.0, 716.0), (-4.0, 717.0), (-4.0, 715.0), (-4.0, 716.0), (-5.0, 715.0), (-4.0, 716.0), (-4.0, 715.0), (-3.0, 716.0), (-5.0, 716.0), (-4.0, 716.0), (-4.0, 716.0), (-4.0, 716.0), (-4.0, 714.0), (-4.0, 716.0), (-4.0, 714.0), (-5.2000732421875, 714.5999908447266), (-4.0, 716.0), (-8.0, 714.0), (-5.0, 715.0), (-4.0, 714.0), (-5.0, 716.0), (-5.0, 715.0), (-3.0, 714.0), (-4.0, 716.0), (-5.0, 714.0), (-4.0, 716.0), (-3.60003662109375, 715.1999816894531), (-6.7999267578125, 712.800048828125), (-4.7999267578125, 717.6000671386719), (-3.600006103515625, 715.2000427246094), (-4.79998779296875, 716.4000244140625), (-4.800048828125, 716.4000244140625), (-6.0, 714.0), (-4.800048828125, 716.4000549316406), (-4.79998779296875, 715.2000732421875), (-3.5999755859375, 716.4000549316406), (-5.0, 715.2000122070312), (-4.79998779296875, 716.4000396728516), (-4.800018310546875, 716.4000396728516), (-3.60003662109375, 716.4000091552734), (-4.800048828125, 716.4000091552734), (-3.5999755859375, 716.4000549316406), (-4.08001708984375, 716.8800201416016), (-3.5999755859375, 716.4000549316406), (-3.60003662109375, 716.4000244140625), (-3.5999755859375, 716.4000244140625), (-2.5999755859375, 716.0000610351562), (-5.280029296875, 715.9200134277344), (-4.79998779296875, 715.2000427246094), (-3.5999755859375, 715.2000122070312), (-5.39996337890625, 716.0000610351562), (-4.79998779296875, 716.4000091552734), (-3.600006103515625, 715.2000122070312), (-6.0, 712.8000030517578), (-3.60009765625, 714.0000610351562), (-4.79998779296875, 716.4000549316406), (-3.600006103515625, 715.2000579833984), (-4.800048828125, 716.4000244140625), (-3.5999755859375, 714.0000476837158), (-4.7999267578125, 714.0000305175781), (-3.5999755859375, 716.4000244140625), (-3.3599853515625, 716.4000549316406), (-3.5999755859375, 716.4000549316406), (-3.5999755859375, 714.0000114440918), (-5.0, 714.4000244140625), (-3.600006103515625, 716.400016784668), (-3.79998779296875, 716.800048828125), (-3.5999755859375, 714.0000457763672), (-3.600006103515625, 715.2000198364258), (-2.4000244140625, 714.0000305175781), (-4.79998779296875, 712.800048828125), (-4.79998779296875, 715.1999816894531), (-4.79998779296875, 715.1999816894531), (-2.8800048828125, 717.1200408935547), (-4.32000732421875, 717.1200256347656), (-2.8800048828125, 715.6800231933594), (-4.32000732421875, 717.1200256347656), (-5.75994873046875, 714.2400207519531), (-4.32000732421875, 715.6800079345703), (-4.319976806640625, 715.6800384521484), (-4.32000732421875, 715.6800079345703), (-5.1842041015625, 713.0879974365234), (-4.32000732421875, 715.6800079345703), (-2.8800048828125, 714.2400054931641), (-4.3199462890625, 712.800048828125), (-2.8800048828125, 715.6800384521484), (-2.8800048828125, 714.2400379180908), (-4.320068359375, 714.2400512695312), (-2.8800048828125, 714.2400360107422), (-4.3199462890625, 714.2400360107422), (-4.32000732421875, 715.6800231933594), (-4.32000732421875, 715.6800231933594)]\n"
     ]
    }
   ],
   "source": [
    "for mc in match_combinations:\n",
    "    print([(pt1[0]-pt2[0],pt1[1]-pt2[1]) for pt1,pt2 in alignment_result[\"alignment_data\"][tuple(mc)]['estimated_translation_inliers']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
