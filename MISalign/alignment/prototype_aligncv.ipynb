{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Data Ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototyping_datafolder=r\"C:\\Users\\drago\\Box\\p_MIS-MISalign\\data_AlignCV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir,path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=dict()\n",
    "for datafolder in listdir(prototyping_datafolder):\n",
    "    for sample in listdir(path.join(prototyping_datafolder,datafolder)):\n",
    "        entry=dict()\n",
    "        entry[\"dataset\"]=datafolder\n",
    "        entry[\"path\"]=path.join(prototyping_datafolder,datafolder,sample)\n",
    "        data_set[sample]=entry\n",
    "df=pd.DataFrame(data_set).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0].path)\n",
    "display(df[df.dataset==\"data_nov\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PILImage.open(df.iloc[0].path).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.opencv.org/4.x/d5/de5/tutorial_py_setup_in_windows.html\n",
    "# https://pypi.org/project/opencv-python/#manual-builds\n",
    "# %pip install opencv-python\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html\n",
    "# https://docs.opencv.org/4.x/db/d27/tutorial_py_table_of_contents_feature2d.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT https://docs.opencv.org/4.x/da/df5/tutorial_py_sift_intro.html\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "img = cv.imread(df.iloc[0].path)\n",
    "gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    " \n",
    "sift = cv.SIFT_create()\n",
    "kp = sift.detect(gray,None)\n",
    " \n",
    "# img=cv.drawKeypoints(gray,kp,img)\n",
    "img=cv.drawKeypoints(gray,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    " \n",
    "# cv.imshow('sift_keypoints',img)\n",
    "PILImage.fromarray(img).show()\n",
    "# display(PILImage.fromarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp,des = sift.compute(gray,kp)\n",
    "display(des.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.opencv.org/4.x/d1/d89/tutorial_py_orb.html\n",
    "img = cv.imread(df.iloc[-2].path)\n",
    "gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Initiate ORB detector\n",
    "orb = cv.ORB_create(nfeatures=500,edgeThreshold=5)\n",
    " \n",
    "# find the keypoints with ORB\n",
    "kp = orb.detect(gray,None)\n",
    " \n",
    "# compute the descriptors with ORB\n",
    "kp, des = orb.compute(gray, kp)\n",
    " \n",
    "# draw only keypoints location,not size and orientation\n",
    "# img2 = cv.drawKeypoints(gray, kp, None, color=(0,255,0), flags=0)\n",
    "img2=cv.drawKeypoints(gray,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "PILImage.fromarray(img2).show()\n",
    "# PILImage.fromarray(img2).save(\"241210_ORB_sem3_nf500_et5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(des.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.opencv.org/4.x/dc/dc3/tutorial_py_matcher.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brute-Force Matching w/ ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "img1 = cv.imread(df.iloc[0].path,cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "img2 = cv.imread(df.iloc[1].path,cv.IMREAD_GRAYSCALE) # trainImage\n",
    " \n",
    "# Initiate ORB detector\n",
    "orb = cv.ORB_create()\n",
    " \n",
    "# find the keypoints and descriptors with ORB\n",
    "kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "kp2, des2 = orb.detectAndCompute(img2,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create BFMatcher object\n",
    "bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    " \n",
    "# Match descriptors.\n",
    "matches = bf.match(des1,des2)\n",
    " \n",
    "# Sort them in the order of their distance.\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    " \n",
    "# Draw first 10 matches.\n",
    "img3 = cv.drawMatches(img1,kp1,img2,kp2,matches[:10],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    " \n",
    "plt.imshow(img3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp2[matches[0].trainIdx].pt\n",
    "kp1[matches[0].queryIdx].pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,match in enumerate(matches[:]):\n",
    "    train_pt=kp2[match.trainIdx].pt\n",
    "    query_pt=kp1[match.queryIdx].pt\n",
    "    x_offset=train_pt[0]-query_pt[0]\n",
    "    y_offset=train_pt[1]-query_pt[1]\n",
    "    # print([x_offset],[y_offset])\n",
    "    # plt.plot([0,x_offset],[0,y_offset],alpha=0.1)\n",
    "    plt.plot([x_offset],[y_offset],\"o\",alpha=0.05,markersize=20)\n",
    "    if i<50:\n",
    "        plt.plot([0,x_offset],[0,y_offset],alpha=0.05)\n",
    "plt.xlim([-1200,1200])\n",
    "plt.ylim([-800,800])\n",
    "plt.title(\"Matches Visualized - all matches dots - top 50 matches lines - 0.05 alpha\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paused to focus on moving forward with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paused to focus on moving forward with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_df=df[df.dataset==\"data_hdf\"].copy() # 2x2 high distinct feature set\n",
    "set_df=df[df.dataset==\"data_sem\"].copy() # 4x1 low overlap set\n",
    "set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_data=dict()\n",
    "for name,sample in set_df.iterrows():\n",
    "    # print(sample)\n",
    "    img = cv.imread(sample.path, cv.IMREAD_GRAYSCALE)\n",
    "    orb = cv.ORB_create(edgeThreshold=5)\n",
    "    kp, des = orb.detectAndCompute(img,None)\n",
    "    orb_data[name]={\"img\":img,\"kp\":kp,\"des\":des}\n",
    "orb_df=pd.DataFrame(orb_data).T\n",
    "orb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width=2560\n",
    "img_height=1672\n",
    "match_combs=combinations(set_df.index.to_list(),2)\n",
    "# print(list(match_combs))\n",
    "match_data=dict()\n",
    "for m1,m2 in match_combs:\n",
    "    print(m1,m2)\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(orb_df[\"des\"][m1],orb_df[\"des\"][m2])\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    img3 = cv.drawMatches(orb_df[\"img\"][m1],orb_df[\"kp\"][m1],orb_df[\"img\"][m2],orb_df[\"kp\"][m2],matches[:10],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    plt.imshow(img3)\n",
    "    plt.savefig(f\"241211_OCV_MOSet_{m1[7:11]}-{m2[10:11]}-matches.png\",bbox_inches=\"tight\",dpi=300)\n",
    "    plt.show()\n",
    "    for i,match in enumerate(matches[:]):\n",
    "        train_pt=orb_df[\"kp\"][m2][match.trainIdx].pt\n",
    "        query_pt=orb_df[\"kp\"][m1][match.queryIdx].pt\n",
    "        x_offset=train_pt[0]-query_pt[0]\n",
    "        y_offset=train_pt[1]-query_pt[1]\n",
    "        plt.plot([x_offset],[y_offset],\"o\",alpha=0.05,markersize=20)\n",
    "        if i<50:\n",
    "            plt.plot([0,x_offset],[0,y_offset],alpha=0.05)\n",
    "    plt.xlim([-img_width,img_width])\n",
    "    plt.ylim([-img_height,img_height])\n",
    "    plt.savefig(f\"241211_OCV_MOSet_{m1[7:11]}-{m2[10:11]}-offsets.png\",bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offset Determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototyping\n",
    "- lro2-3 for clean-defined\n",
    "- lro0-2 for fuzzy rotated\n",
    "- lro1-2 for similar feature but no match\n",
    "- hdf0-2 for corner barely match\n",
    "- hdf0-1 for clean-defined\n",
    "- hdf1-3 for clean-defined\n",
    "- lov2-3 for fuzzy match\n",
    "- lov1-2 for fuzzy match\n",
    "- ldf0-3 for clean match w/ noise\n",
    "- ldf2-3 for clean match w/ noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_short=[\"sem0\",\"sem1\",\"sem2\",\"sem3\",\"sem4\",\"sem5\"]#[\"lro0\",\"lro1\",\"lro2\",\"lro3\",\"hdf0\",\"hdf1\",\"hdf2\",\"hdf3\",\"lov1\",\"lov2\",\"lov3\",\"ldf0\",\"ldf2\",\"ldf3\"]\n",
    "samples=pd.DataFrame([df[df.index.str.contains(x)].iloc[0] for x in samples_short])\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_data=dict()\n",
    "for name,sample in samples.iterrows():\n",
    "    # print(sample)\n",
    "    img = cv.imread(sample.path, cv.IMREAD_GRAYSCALE)\n",
    "    orb = cv.ORB_create(nfeatures=500,edgeThreshold=5)\n",
    "    kp, des = orb.detectAndCompute(img,None)\n",
    "    orb_data[name]={\"img\":img,\"kp\":kp,\"des\":des}\n",
    "orb_df=pd.DataFrame(orb_data).T\n",
    "orb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_combs=combinations(orb_df.index.to_list(),2)\n",
    "# match_combs=((\"lro2\",\"lro3\"),(\"lro0\",\"lro2\"),(\"lro1\",\"lro2\"),(\"hdf0\",\"hdf2\"),(\"hdf0\",\"hdf1\"),(\"hdf1\",\"hdf3\"),(\"lov2\",\"lov3\"),(\"lov1\",\"lov2\"),(\"ldf0\",\"ldf3\"),(\"ldf2\",\"ldf3\"))\n",
    "# match_combs=((\"sem0\",\"sem1\"),(\"sem2\",\"sem3\"),(\"sem3\",\"sem4\"),(\"sem4\",\"sem5\"),(\"sem3\",\"sem5\"))\n",
    "match_combs=((\"sem0\",\"sem1\"),(\"sem2\",\"sem3\"),(\"sem3\",\"sem4\"),(\"sem4\",\"sem5\"),(\"sem3\",\"sem5\"))\n",
    "match_combs=[(df.index[df.index.str.contains(x[0])][0],df.index[df.index.str.contains(x[1])][0]) for x in match_combs]\n",
    "\n",
    "match_combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width=2560\n",
    "img_height=1672\n",
    "for m1,m2 in match_combs:\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(orb_df[\"des\"][m1],orb_df[\"des\"][m2])\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    print([m.distance for m in matches])\n",
    "    offset_grid=np.zeros((2*img_width,2*img_height),dtype=float) # change this to match 2x image distance.(3200,2400)\n",
    "    for i,match in enumerate(matches[:]):\n",
    "        train_pt=orb_df[\"kp\"][m2][match.trainIdx].pt\n",
    "        query_pt=orb_df[\"kp\"][m1][match.queryIdx].pt\n",
    "        x_offset_adj=int(train_pt[0]-query_pt[0]+img_width) #1600/1200 centers in numpy array/image.\n",
    "        y_offset_adj=int(train_pt[1]-query_pt[1]+img_height)\n",
    "        offset_grid[x_offset_adj,y_offset_adj]+=1000/(match.distance**2)\n",
    "    offset_grid=ndimage.gaussian_filter(offset_grid,10)\n",
    "    print(m1,m2,\"Offset:\",np.array(np.unravel_index(np.argmax(offset_grid),offset_grid.shape))-np.array([img_width,img_height]))\n",
    "    plt.title(\" \".join([m1,m2,str(tuple(np.array(np.unravel_index(np.argmax(offset_grid),offset_grid.shape))-np.array([img_width,img_height]))),f\"{offset_grid.max():.5f}\"]))\n",
    "    plt.imshow(offset_grid.T)\n",
    "    plt.colorbar()\n",
    "    plt.savefig(f\"241210_OffsetMap_{m1[7:11]}-{m2[10:11]}-offmap-1000imds-g10_nf500_et5.png\",bbox_inches=\"tight\",dpi=300)\n",
    "    plt.show()\n",
    "    # img3 = cv.drawMatches(orb_df[\"img\"][m1],orb_df[\"kp\"][m1],orb_df[\"img\"][m2],orb_df[\"kp\"][m2],matches[:10],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    # plt.imshow(img3)\n",
    "    # plt.savefig(f\"240815_OCV_MOSet_{m1[7:11]}-{m2[10:11]}-matches.png\",bbox_inches=\"tight\",dpi=300)\n",
    "    # plt.show()\n",
    "    # for i,match in enumerate(matches[:]):\n",
    "    #     train_pt=orb_df[\"kp\"][m2][match.trainIdx].pt\n",
    "    #     query_pt=orb_df[\"kp\"][m1][match.queryIdx].pt\n",
    "    #     x_offset=train_pt[0]-query_pt[0]\n",
    "    #     y_offset=train_pt[1]-query_pt[1]\n",
    "    #     plt.plot([x_offset],[y_offset],\"o\",alpha=0.05,markersize=20)\n",
    "    #     if i<50:\n",
    "    #         plt.plot([0,x_offset],[0,y_offset],alpha=0.05)\n",
    "    # plt.xlim([-1600,1600])\n",
    "    # plt.ylim([-1200,1200])\n",
    "    # plt.savefig(f\"240815_OCV_MOSet_{m1[7:11]}-{m2[10:11]}-offsets.png\",bbox_inches=\"tight\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing way to get/compare local maxima. Code from `https://stackoverflow.com/questions/9111711/get-coordinates-of-local-maxima-in-2d-array-above-certain-value`\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "neighborhood_size = 50\n",
    "threshold = 0.0005\n",
    "\n",
    "data = offset_grid.T\n",
    "\n",
    "data_max = ndimage.maximum_filter(data, neighborhood_size)\n",
    "maxima = (data == data_max)\n",
    "data_min = ndimage.minimum_filter(data, neighborhood_size)\n",
    "diff = ((data_max - data_min) > threshold)\n",
    "maxima[diff == 0] = 0\n",
    "\n",
    "labeled, num_objects = ndimage.label(maxima)\n",
    "xy = np.array(ndimage.center_of_mass(data, labeled, range(1, num_objects+1)))\n",
    "\n",
    "plt.imshow(data)\n",
    "\n",
    "plt.autoscale(False)\n",
    "plt.plot(xy[:, 1], xy[:, 0], 'rx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-array/blended match>offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_from=\"sample_sem0.tif\"\n",
    "# image_to=\"sample_sem1.tif\"\n",
    "# sem 0 to sem 1: [48 1101] from offset map\n",
    "# image_from=\"sample_sem3.tif\"\n",
    "# image_to=\"sample_sem5.tif\"\n",
    "# sem 3 to sem 5: No real relation\n",
    "image_from=\"sample_sem3.tif\"\n",
    "image_to=\"sample_sem4.tif\"\n",
    "# 3>4 has distinct relation in offset map\n",
    "\n",
    "matches = bf.match(orb_df[\"des\"][image_from],orb_df[\"des\"][image_to])\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "pts_from=np.array([orb_df[\"kp\"][image_from][match.queryIdx].pt for match in matches])\n",
    "pts_to=np.array([orb_df[\"kp\"][image_to][match.trainIdx].pt for match in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "eAP2D=cv.estimateAffinePartial2D(pts_from,pts_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X,Y:\",eAP2D[0][:,2])\n",
    "#cos^2 + sin^2 = 1 >> rotation/scale component of matrix =s^2\n",
    "print(\"Rotation & Scale Matrix:\",eAP2D[0][:,:2])\n",
    "eAP2D_scalex=(eAP2D[0][0,0]**2+eAP2D[0][0,1]**2)**0.5\n",
    "eAP2D_scaley=(eAP2D[0][1,1]**2+eAP2D[0][1,0]**2)**0.5\n",
    "print(\"Scale X,Y:\",[eAP2D_scalex,eAP2D_scaley])\n",
    "eAP2D_rotation=np.arctan(eAP2D[0][0,1]/eAP2D[0][1,1])\n",
    "print(\"Rotation(Rad/Deg):\",eAP2D_rotation,\"/\",eAP2D_rotation*180/np.pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Inliers:\",np.sum(eAP2D[1]))\n",
    "for pt_from,pt_to,in_out in zip(pts_from,pts_to,eAP2D[1]):\n",
    "    if in_out:\n",
    "        print(\"X,Y:\",pt_to[0]-pt_from[0],pt_to[1]-pt_from[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set implementation\n",
    "Also grabbing all need coded/imports/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "from math import dist\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run data import from first section to setup `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_short=[\"sem0\",\"sem1\",\"sem2\",\"sem3\",\"sem4\",\"sem5\"]#\n",
    "# samples_short=[\"lro0\",\"lro1\",\"lro2\",\"lro3\",\"hdf0\",\"hdf1\",\"hdf2\",\"hdf3\",\"lov1\",\"lov2\",\"lov3\",\"ldf0\",\"ldf2\",\"ldf3\"]\n",
    "samples=pd.DataFrame([df[df.index.str.contains(x)].iloc[0] for x in samples_short])\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_combs=combinations(orb_df.index.to_list(),2)\n",
    "match_combs=((\"sem0\",\"sem1\"),(\"sem2\",\"sem3\"),(\"sem3\",\"sem4\"),(\"sem4\",\"sem5\"),(\"sem3\",\"sem5\"))\n",
    "# match_combs=((\"lro2\",\"lro3\"),(\"lro0\",\"lro2\"),(\"lro1\",\"lro2\"),(\"hdf0\",\"hdf2\"),(\"hdf0\",\"hdf1\"),(\"hdf1\",\"hdf3\"),(\"lov2\",\"lov3\"),(\"lov1\",\"lov2\"),(\"ldf0\",\"ldf3\"),(\"ldf2\",\"ldf3\"))\n",
    "# match_combs=((\"lov2\",\"lov3\"),(\"lov1\",\"lov2\"),(\"ldf0\",\"ldf3\"))\n",
    "match_combs=[(df.index[df.index.str.contains(x[0])][0],df.index[df.index.str.contains(x[1])][0]) for x in match_combs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_data=dict()\n",
    "for name,sample in samples.iterrows():\n",
    "    # print(sample)\n",
    "    img = cv.imread(sample.path, cv.IMREAD_GRAYSCALE)\n",
    "    orb = cv.ORB_create(nfeatures=4000,edgeThreshold=5)\n",
    "    kp, des = orb.detectAndCompute(img,None)\n",
    "    orb_data[name]={\"img\":img,\"kp\":kp,\"des\":des}\n",
    "orb_df=pd.DataFrame(orb_data).T\n",
    "orb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_refs={#values for offset from offsetmap\n",
    "    (\"sem0\",\"sem1\"):[48, 1101],\n",
    "    (\"sem2\",\"sem3\"):[84, 1192],\n",
    "    (\"sem3\",\"sem4\"):[14, 682],\n",
    "    (\"sem4\",\"sem5\"):[1,1558],\n",
    "    (\"sem3\",\"sem5\"):[673,-538]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m1,m2 in match_combs:\n",
    "    print(m1,m2)\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "    \n",
    "    matches = bf.match(orb_df[\"des\"][m1],orb_df[\"des\"][m2])\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    matches = matches[:int(len(matches)*(1/8))]\n",
    "    # matches = matches[:10]\n",
    "\n",
    "    pts_from=np.array([orb_df[\"kp\"][m1][match.queryIdx].pt for match in matches])\n",
    "    pts_to=np.array([orb_df[\"kp\"][m2][match.trainIdx].pt for match in matches])\n",
    "\n",
    "    eAP2D=cv.estimateAffinePartial2D(pts_from,pts_to)\n",
    "\n",
    "    eAP2D_translationx=eAP2D[0][0,2]\n",
    "    eAP2D_translationy=eAP2D[0][1,2]\n",
    "    print(f\"X,Y:{eAP2D_translationx:0.1f}, {eAP2D_translationy:0.1f}\")\n",
    "    print(\"Rotation & Scale Matrix: \\n\",eAP2D[0][:,:2])\n",
    "    eAP2D_scalex=(eAP2D[0][0,0]**2+eAP2D[0][0,1]**2)**0.5\n",
    "    eAP2D_scaley=(eAP2D[0][1,1]**2+eAP2D[0][1,0]**2)**0.5\n",
    "    print(f\"Scale X,Y: {eAP2D_scalex:0.3f}, {eAP2D_scaley:0.3f}\")\n",
    "    eAP2D_rotation=np.arctan(eAP2D[0][0,1]/eAP2D[0][1,1])\n",
    "    print(f\"Rotation(Rad/Deg): {eAP2D_rotation:0.3f} /{eAP2D_rotation*180/np.pi:0.1f}\")\n",
    "    print(\"Inliers:\",np.sum(eAP2D[1]))\n",
    "    for pt_from,pt_to,in_out in zip(pts_from,pts_to,eAP2D[1]):\n",
    "        if in_out:\n",
    "            print(f\"X,Y:{pt_from[0]-pt_to[0]:0.1f}, {pt_from[1]-pt_to[1]:0.1f}\")\n",
    "    \n",
    "    distances_inlier=np.array([(i,match.distance) for i,(match,in_out) in enumerate(zip(matches,eAP2D[1])) if in_out])\n",
    "    distances_outlier=np.array([(i,match.distance) for i,(match,in_out) in enumerate(zip(matches,eAP2D[1])) if not in_out])\n",
    "    plt.figure()\n",
    "    plt.plot(distances_inlier[:,0],distances_inlier[:,1],\"gx\")\n",
    "    try:\n",
    "        plt.plot(distances_outlier[:,0],distances_outlier[:,1],\"r.\")\n",
    "    except IndexError:\n",
    "        print(\"No Outliers\")\n",
    "    plt.xlabel(\"match index\")\n",
    "    plt.ylabel(\"match distance\")\n",
    "    plt.title(f\"{m1}-{m2} in/out distances\")\n",
    "    plt.show()\n",
    "\n",
    "    # ### Sanity check with offset map\n",
    "    # img_width=1600#2560\n",
    "    # img_height=1200#1672\n",
    "    # offset_grid=np.zeros((2*img_width,2*img_height),dtype=float) # change this to match 2x image distance.(3200,2400)\n",
    "    # for i,match in enumerate(matches[:]):\n",
    "    #     train_pt=orb_df[\"kp\"][m2][match.trainIdx].pt\n",
    "    #     query_pt=orb_df[\"kp\"][m1][match.queryIdx].pt\n",
    "    #     x_offset_adj=int(train_pt[0]-query_pt[0]+img_width) #1600/1200 centers in numpy array/image.\n",
    "    #     y_offset_adj=int(train_pt[1]-query_pt[1]+img_height)\n",
    "    #     offset_grid[x_offset_adj,y_offset_adj]+=1000/(match.distance**2)\n",
    "    # offset_grid=ndimage.gaussian_filter(offset_grid,10)\n",
    "    # print(m1,m2,\"Offset:\",np.array(np.unravel_index(np.argmax(offset_grid),offset_grid.shape))-np.array([img_width,img_height]))\n",
    "    # plt.title(\" \".join([m1,m2,str(tuple(np.array(np.unravel_index(np.argmax(offset_grid),offset_grid.shape))-np.array([img_width,img_height]))),f\"{offset_grid.max():.5f}\"]))\n",
    "    # plt.imshow(offset_grid.T)\n",
    "    # plt.colorbar()\n",
    "    # # plt.savefig(f\"241210_OffsetMap_{m1[7:11]}-{m2[10:11]}-offmap-1000imds-g10_nf500_et5.png\",bbox_inches=\"tight\",dpi=300)\n",
    "    # plt.show()\n",
    "    # match_refs[(m1[7:11],m2[7:11])]=list(np.array(np.unravel_index(np.argmax(offset_grid),offset_grid.shape))-np.array([img_width,img_height]))\n",
    "    # ###\n",
    "\n",
    "    top10_offsets=np.array([(pt_to[0]-pt_from[0],pt_to[1]-pt_from[1]) for pt_from,pt_to in zip(pts_from[:int(len(matches)*(1/10))],pts_to[:int(len(matches)*(1/10))])])\n",
    "    top50_offsets=np.array([(pt_to[0]-pt_from[0],pt_to[1]-pt_from[1]) for pt_from,pt_to in zip(pts_from[int(len(matches)*(1/10)):int(len(matches)*(1/2))],pts_to[int(len(matches)*(1/10)):int(len(matches)*(1/2))])])\n",
    "    remaining_offsets=np.array([(pt_to[0]-pt_from[0],pt_to[1]-pt_from[1]) for pt_from,pt_to in zip(pts_from[int(len(matches)*(1/2)):],pts_to[int(len(matches)*(1/2)):])])\n",
    "    plt.figure()\n",
    "    plt.plot(top10_offsets[:,0],top10_offsets[:,1],\"gx\",alpha=0.1)\n",
    "    plt.plot(top50_offsets[:,0],top50_offsets[:,1],\"yx\",alpha=0.1)\n",
    "    plt.plot(remaining_offsets[:,0],remaining_offsets[:,1],\"rx\",alpha=0.1)\n",
    "    plt.xlabel(\"x offset\")\n",
    "    plt.ylabel(\"y offset\")\n",
    "    plt.title(f\"{m1}-{m2} match offsets top 10%/top 50%/remaining\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    distances_metric_ref=np.array([(dist((pt_to[0]-pt_from[0],pt_to[1]-pt_from[1]),match_refs[(m1[7:11],m2[7:11])]),match.distance) for match,pt_from,pt_to in zip(matches,pts_from,pts_to)])\n",
    "    plt.figure()\n",
    "    plt.plot(distances_metric_ref[:,0],distances_metric_ref[:,1],\"x\")\n",
    "    plt.xlabel(\"ref distance\")\n",
    "    plt.ylabel(\"match distance\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.title(f\"{m1}-{m2} ref/match distances\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # plt.title(\" \".join([m1,m2,str(tuple(np.array(np.unravel_index(np.argmax(offset_grid),offset_grid.shape))-np.array([img_width,img_height]))),f\"{offset_grid.max():.5f}\"]))\n",
    "    # plt.imshow(offset_grid.T)\n",
    "    # plt.colorbar()\n",
    "    # plt.savefig(f\"241210_OffsetMap_{m1[7:11]}-{m2[10:11]}-offmap-1000imds-g10_nf500_et5.png\",bbox_inches=\"tight\",dpi=300)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionalizing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import abspath\n",
    "from sys import path\n",
    "path.insert(0, abspath(\"../..\"))  # Repository directory relative to this file.\n",
    "from MISalign.model.mis_file import MisFile,load_mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_filepath=r\"..\\\\..\\example\\data\\set_a\\mymis.mis\"\n",
    "mis_project=load_mis(mis_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_myimages01.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\MISaligned\\\\MISalign_public\\\\example\\\\data\\\\set_a\\\\a_myimages01.jpg',\n",
       " 'a_myimages02.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\MISaligned\\\\MISalign_public\\\\example\\\\data\\\\set_a\\\\a_myimages02.jpg',\n",
       " 'a_myimages03.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\MISaligned\\\\MISalign_public\\\\example\\\\data\\\\set_a\\\\a_myimages03.jpg',\n",
       " 'a_myimages04.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\MISaligned\\\\MISalign_public\\\\example\\\\data\\\\set_a\\\\a_myimages04.jpg',\n",
       " 'a_myimages05.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\MISaligned\\\\MISalign_public\\\\example\\\\data\\\\set_a\\\\a_myimages05.jpg',\n",
       " 'a_myimages06.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\MISaligned\\\\MISalign_public\\\\example\\\\data\\\\set_a\\\\a_myimages06.jpg',\n",
       " 'a_myimages07.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\MISaligned\\\\MISalign_public\\\\example\\\\data\\\\set_a\\\\a_myimages07.jpg',\n",
       " 'a_myimages08.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\MISaligned\\\\MISalign_public\\\\example\\\\data\\\\set_a\\\\a_myimages08.jpg',\n",
       " 'a_myimages09.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\MISaligned\\\\MISalign_public\\\\example\\\\data\\\\set_a\\\\a_myimages09.jpg',\n",
       " 'a_myimages10.jpg': 'c:\\\\Users\\\\drago\\\\Documents\\\\MISaligned\\\\MISalign_public\\\\example\\\\data\\\\set_a\\\\a_myimages10.jpg'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_project.get_image_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageManager():\n",
    "    def __init__(self,image_names_paths:dict):\n",
    "        pass\n",
    "    def lookup_name(short_name:str)->str:\n",
    "        pass\n",
    "\n",
    "class ORBManager():\n",
    "    def __init__(self,image_names_paths:dict):\n",
    "        pass\n",
    "\n",
    "def generate_match_combinations(strategy,**kwargs)-> list[list]: \n",
    "    if strategy==\"order\":\n",
    "        return generate_match_combinations_in_order(kwargs[\"order\"])\n",
    "    elif strategy==\"short_pairs\":\n",
    "        return generate_match_combinations_from_short_pairs(kwargs[\"short_pairs\"],kwargs[\"short_lookup\"])\n",
    "    elif strategy==\"all\":\n",
    "        return generate_match_combinations_all_combinations(kwargs[\"all\"])\n",
    "    elif strategy==\"search\":\n",
    "        return generate_match_combinations_all_combinations(kwargs[\"search\"],kwargs[\"all\"])\n",
    "    else:\n",
    "        raise ValueError(f\"'{strategy}' is not a valid strategy.\")\n",
    "def generate_match_combinations_in_order(order:list):\n",
    "    pass\n",
    "def generate_match_combinations_from_short_pairs(short_pairs:list[list],short_lookup:ImageManager.lookup_name):\n",
    "    pass\n",
    "def generate_match_combinations_all_combinations(items:list):\n",
    "    pass\n",
    "def generate_match_combinations_search(search:str,items:list):\n",
    "    pass\n",
    "\n",
    "def generate_match_bf(image1:str,image2:str,ORB_parameters:dict,ORBM:ORBManager,match_reduction_ratio:float):\n",
    "    pass\n",
    "\n",
    "def estimate_translation(\n",
    "        matches,\n",
    "        limit_affine_rotation=0.01, #maximum affine rotation without correction i.e. -0.01rad to +0.01rad rotations are acceptable.\n",
    "        limit_affine_scale=0.01, #maximum affine scale without correction i.e. 0.99 scale to 1.01 scale are acceptable.\n",
    "        limit_minimum_points=5, #minimum number of matched points for succesful translation estimate.\n",
    "        limit_inlier_consistency=0.5 #minimum fraction of matched points that must be consistent\n",
    "    )->list[list,bool]:\n",
    "    pass\n",
    "\n",
    "def cv_align(match_combinations:list[list],ImageM:ImageManager):\n",
    "    pass\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
